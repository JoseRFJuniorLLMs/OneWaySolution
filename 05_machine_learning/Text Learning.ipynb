{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas and Sklearn were used on this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 600 entries, 03000000012017_6622932_inicial_lorena.pdf to 02000012462017_8103027_peticao_inicial_0000803-08.2017.5.11.0017.pdf\n",
      "Data columns (total 2 columns):\n",
      "cod      600 non-null int64\n",
      "words    599 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../04_merged_content/dataset.csv', sep = ';',\n",
    "                   names=['name','cod','words'], index_col='name', header=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset built on stage 04 were load and had its columns renamed, 'Nome do Arquivo' became 'name', 'iCodDocumento' to 'cod' and 'words' for 'Keyphrases', besides, 'name' column was set as index. Some info was given and it is notable that the column 'words' appears to have a null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02000008202017_7611302_20170413_FEDERAL_SEGUROS_-_00820_2017_-_0224726-83.2011.8.04.0001_16.pdf</th>\n",
       "      <td>5083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     cod words\n",
       "name                                                          \n",
       "02000008202017_7611302_20170413_FEDERAL_SEGUROS...  5083   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na = data[data.words.isnull()].index.values\n",
    "data[data.words.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(na, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('clean_data.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null value hypothesis was tested and confirmed. It was decided to discard this line since there were no words to be analyzed. A new dataset was created and stored on a csv file as a [final and clean dataset](./clean_data.csv), so it can be used by others programs and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.words, data.cod, test_size = 0.2, random_state=42)\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was split into train and test lines and its columns into 'x' and 'y', representing 'word' column as features and 'cod' as labels. Train dataset with 479 lines and 120 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 40583)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "vec_train = vec.fit_transform(x_train)\n",
    "vec_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [sklearn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) 'CountVectorizer' converts a collection of text documents to a matrix of token count, that is, every word becomes a column and each line counts its frequency on a document. As shown above, 40583 words were found and counted in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_test = vec.transform(x_test)\n",
    "predictions = clf.predict(vec_test)\n",
    "clf.score(vec_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Nayve Bayes was chosen to build a classification model that can predict a document 'iCodDocument' (cod) based on the words of a document keyphrases using supervised machine learning. This reached a great score of over 94% on top of the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       5070       0.96      0.97      0.97       109\n",
      "       5083       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.94      0.94      0.94       120\n",
      "\n",
      "[[106   3]\n",
      " [  4   7]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions))\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional metrics were calculated to give a better understanding of the model. As shown, great values were archieved by '5070' label, and goods values for '5083'. Probably, this discrepancy was caused by the low number of '5083' labels in relation to the '5070' labels, which suggests that larger number of documents that have '5083' label could improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
